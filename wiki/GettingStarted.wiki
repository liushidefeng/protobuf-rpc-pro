= Getting Started =

The [http://protobuf-rpc-pro.googlecode.com/svn/trunk/protobuf-rpc-pro-duplex/src/test/java/com/googlecode/protobuf/pro/duplex/example example] source package contains several runnable examples. 

The examples use a simple [http://protobuf-rpc-pro.googlecode.com/svn/trunk/protobuf-rpc-pro-duplex/src/test/protos/pingpong.proto PingPong] service where a client can call "ping" on a server.

== Client Code ==

Firstly we declare who the client is and who the server is that we're going to connect to. Note that the client does not actually bind to port 1234, it is just used as a "name".
{{{
	PeerInfo client = new PeerInfo("clientHostname", 1234);
	PeerInfo server = new PeerInfo("serverHostname", 8080);
}}}
The main client class to start with is a DuplexTcpClientBootstrap. Netty practitioners will know all about this. Through it you can configure all relevant Socket options like buffer sizes, no delay etc. 
If a client is also going to be acting as a server, it is necessary to setup an RpcCallExecutor who's purpose it is to run the calls ( using threads separate from the IO Threads ).
{{{    	
    	ThreadPoolCallExecutor executor = new ThreadPoolCallExecutor(3, 10);

    	DuplexTcpClientBootstrap bootstrap = new DuplexTcpClientBootstrap(
        		client, 
        		new NioClientSocketChannelFactory(
                Executors.newCachedThreadPool(),
                Executors.newCachedThreadPool()),
                executor);
}}}
In order to customize TCP settings, you can use all Netty socket options and the "connectResponseTimeoutMillis" which is introduced to put an upper bound on the "peering" time.
{{{
    	bootstrap.setOption("connectTimeoutMillis",10000);
        bootstrap.setOption("connectResponseTimeoutMillis",10000);
        bootstrap.setOption("receiveBufferSize", 1048576);
        bootstrap.setOption("tcpNoDelay", false);
}}}
In order to open a TCP connection to the server it is necessary to "peerWith" it. A server will not allow the same client "named" to connect multiple times. ( You can still make more than one connection to the same server from the same "Process", just choose different ports to name them and separate Bootstraps ).
{{{
    	RpcClientChannel channel = bootstrap.peerWith(serverInfo);
}}}
Then you can use the pretty much standard Protocol Buffer services which you have like this.
{{{
	BlockingInterface myService = PingPongService.newBlockingStub(channel);
	RpcController controller = channel.newRpcController();
			
	Ping request = Ping.newBuilder().set....build();
	Pong pong = myService.ping(controller, request);
}}}
The same RpcClientChannel can be used multiple times for calls to the server, using any Service which the server handles. 

In order to service RPC calls on the client side, you just need to register a service implementation with the bootstrap.
{{{
    	bootstrap.getRpcServiceRegistry().registerService(new PingPongServiceImpl());
}}}    	
Service implementations can be added and removed at runtime. Service methods are looked up by "shortname" so the server and client "packaging" need not be identical.

Finally to close the RpcClientChannel so it cannot be used anymore do, call close. On shutdown of the client application you need to call release resources to stop the low-level IO-Threads.
{{{
	channel.close();
	bootstrap.releaseExternalResources();
}}}
	
== Server Code ==

The server side is pretty similar to the client above. The server needs to know "who" it is, and be given a port on which to bind to on the machine it is running on. Note you can configure a local address to bind onto also ( multi-homing support ) through the Netty localAddress option. The server's hostname should normally be the server's hostname which resolves in DNS to the server machine, however it is just a name ( like the client's port is just a name ).
{{{
    	PeerInfo serverInfo = new PeerInfo("serverHostname", 8080);
}}}
You need then to create a DuplexTcpServerBootstrap and provide it an RpcCallExecutor.
{{{
    	ThreadPoolCallExecutor executor = new ThreadPoolCallExecutor(10, 10);
    	
        DuplexTcpServerBootstrap bootstrap = new DuplexTcpServerBootstrap(
        		serverInfo,
                new NioServerSocketChannelFactory(
                        Executors.newCachedThreadPool(),
                        Executors.newCachedThreadPool()),
                executor);
}}}
Then you need to register your server side services with the bootstrap. Again here the registration is dynamic and can change at runtime.
{{{
    	bootstrap.getRpcServiceRegistry().registerService(new DefaultPingPongServiceImpl());
}}}
Finally binding the bootstrap to the TCP port will start off the socket accepting and clients can start to connect.
{{{
        Channel c = bootstrap.bind();
}}}
If you want to track the RPC peering events with clients, use a RpcClientConnectionRegistry or a TcpConnectionEventListener for TCP connection events. This is the mechanism you can use to "discover" RPC clients before they "call" any service.
{{{
    	RpcClientConnectionRegistry eventLogger = new RpcClientConnectionRegistry();
    	bootstrap.registerConnectionEventListener(eventLogger);
}}}
You can then also close the server by closing the channel which the bootstrap is bound to and finally releaseExternalResources on final shutdown.

== Runtime Dependencies ==
The external dependencies have been kept to a minimum. Netty and commons logging are the only compile time dependencies. At runtime an additional logging facility is optional. Compiled against java 1.6.

{{{
		<dependency>
			<groupId>com.google.protobuf</groupId>
			<artifactId>protobuf-java</artifactId>
			<version>2.3.0</version>
		</dependency>
		<dependency>
			<groupId>org.jboss.netty</groupId>
			<artifactId>netty</artifactId>
			<version>3.2.1.Final</version>
		</dependency>
		<dependency>
			<groupId>commons-logging</groupId>
			<artifactId>commons-logging</artifactId>
			<version>1.1.1</version>
		</dependency>
}}}